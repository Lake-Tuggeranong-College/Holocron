# Guide to Creating Your Feedback Form

This form is a critical tool for gathering data for your profile. The data collected must allow you to effectively evaluate your project's goals, design, and user experience.

## Part 1: Setup and Stating Project Goals (The Mandatory Start)

To provide effective feedback, the audience needs to understand what your project was **intended** to achieve.

1. **Choose Your Platform:**    
    - **Recommended: Google Forms** (Digital Collection)
        - **Pros:** Automatically collates all quantitative (number) data into a spreadsheet, making analysis and graphing for Task 3 much easier.
        - **Cons:** Requires reviewers to use a mobile device or computer to fill it out.
    - **Alternative: Google Docs** (Printable Collection)
        - **Pros:** Easy to print, quick for reviewers to fill out by hand.
        - **Cons:** You must manually input all data into a spreadsheet for analysis in Task 3.
2. **Form Title:** Name your form clearly (e.g., "IT Expo Project Feedback: 'Your Project Name' ").
3. **Mandatory Section: Project Goals:** Your very first section **must** clearly state the original goals of your project. This provides context for the reviewers.
    - **Google Forms:** Use a **Paragraph** text field (not a question) at the top of the form.
    - **Google Docs:** Use a clear heading and simple text box or bulleted list directly below the form title.
    - **Content:** Write a short, clear paragraph or a bulleted list summarising the 2â€“3 main objectives of your project (e.g., "The goal of this project was to provide a secure system for tracking inventory using NFC tags and a mobile app.").

## Part 2: Designing Closed (Quantitative) Questions

Closed questions generate measurable data that is easy to quantify and graph in your final report. Use these to evaluate specific criteria.

| **Evaluation Goal**       | **Question Type (Google Forms)** | **Google Docs Equivalent**                        | **Example Question**                                                                                                  |
| ------------------------- | -------------------------------- | ------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- |
| **Usability/Clarity**     | Linear Scale (1-5)               | Create a row of five empty circles/squares.       | "How easy was it to understand the purpose of this project?" (1=Very Difficult, 5=Very Easy)                          |
| **Engagement/Interest**   | Linear Scale (1-5)               | Create a row of five empty circles/squares.       | "How engaging or interesting did you find the project's display/concept?" (1=Not Engaging, 5=Extremely Engaging)      |
| **Aesthetic/Design**      | Multiple Choice                  | Use check boxes or empty squares next to options. | "Which aspect of the project's design did you like best?" (Options: Visual Layout, Colour Scheme, Ease of Navigation) |
| **Overall Effectiveness** | Linear Scale (1-5)               | Create a row of five empty circles/squares.       | "Overall, how effective was this project at meeting its stated goals?" (1=Not Effective, 5=Highly Effective)          |

**Tip:** Stick to a **5-point Likert scale (1-5)** for satisfaction questions, as it is the most effective for generating clear quantitative data for your evaluation.

## Part 3: Designing Open (Qualitative) Questions

Open questions allow users to provide detailed, specific, and unstructured feedback that helps you understand _why_ they gave a particular rating.
1. **Focus on Specific Improvement:** Ask reviewers to suggest one clear action you could take to improve the project.
    - **Example:** "If you were to take this project to the next level, what single feature or change would you recommend?"
2. **Focus on Positive Aspects:** Ask what worked well. This validates your efforts and identifies key strengths.
    - **Example:** "What was the most successful or impressive component of the project?"
3. **General Feedback:** A catch-all for any thoughts you missed.
    - **Example:** "Do you have any other comments or suggestions for the project creator?"

**Implementation in Platforms:**
- **Google Forms:** Use the **Paragraph** answer type for these questions.
- **Google Docs:** Use a simple **line** or a clear box labeled "Please write your answer here" to provide enough space for detailed responses.

### Form Checklist:

- [ ] Does the form start with the **Project Goals**?
- [ ] Do you have a balanced mix of **quantitative (closed)** and **qualitative (open)** questions?
- [ ] Are all questions clear, easy to understand, and relevant to a Year 9/10 audience?
- [ ] Have you set appropriate questions as **"Required"** (for Forms) or clearly indicated they are mandatory (for Docs)?

**Action:** Once drafted, share the form link or the draft document with your teacher for feedback.

# Example Feedback Questions for IT Projects

This document provides examples of effective and ineffective questions for your IT Expo Feedback Form. When designing questions, remember that the key goal is to get **measurable** data (ratings) and **actionable** data (specific suggestions) from your Year 9 and 10 reviewers.

## Quantitative (Closed) Questions

Closed questions are used to generate numerical data. They must be easy to read, focus on a single variable, and use a clear rating scale.

|   |   |   |   |   |
|---|---|---|---|---|
|**Category**|**Good Example (5-Point Scale)**|**Why It's Good**|**Bad Example**|**Why It's Bad**|
|**Clarity**|**Linear Scale (1-5):** "How easy was it to understand the purpose of this project?" _(1=Difficult, 5=Easy)_|Focuses on a single concept (clarity) and uses simple, opposite anchors.|**Linear Scale (1-5):** "Did you find the documentation and presentation slides both helpful and visually appealing?" _(1=No, 5=Yes)_|**Double-Barreled.** It asks about four different things at once. The user can't answer if the slides were appealing but not helpful.|
|**Design/UX**|**Linear Scale (1-5):** "How professional did the overall visual design look?" _(1=Not professional, 5=Highly professional)_|Isolates the visual quality, which is a key evaluation criterion.|**Yes/No:** "Was the user interface good?"|**Not Measurable.** "Good" is subjective. A simple Yes/No answer provides no depth of data for Task 3.|
|**Innovation**|**Linear Scale (1-5):** "To what extent did you find the project concept original or innovative?" _(1=Low, 5=High)_|Directly measures the perceived level of innovation using an intensity scale.|**Checkboxes:** "Check all that apply: Interesting, Fun, Helpful."|**Too Subjective.** These are adjectives, not measurable criteria. They don't help you assess effectiveness against a project goal.|
|**Engagement**|**Linear Scale (1-5):** "I would be interested in seeing the final, working version of this product." _(1=Strongly Disagree, 5=Strongly Agree)_|Uses agreement language to measure future intent and interest in the project.|**Multiple Choice:** "Was it cool or fast?" _(A. Cool, B. Fast, C. Both)_|**Confusing.** This forces a choice between two unrelated characteristics and doesn't use a scale for quantification.|

## Qualitative (Open) Questions

Open questions are used to gather specific, detailed text feedback. They must prompt a helpful response that explains _why_ a reviewer gave a certain rating.

|   |   |   |   |
|---|---|---|---|
|**Good Example**|**Why It's Good**|**Bad Example**|**Why It's Bad**|
|**Focus on Improvement**|"What is the single most important thing the project team should focus on improving next?"|It prompts a **specific, actionable idea**, forcing the reviewer to prioritize their suggestion.|"What did you think of the project?"|
|**Focus on Strengths**|"Identify one specific feature or part of the project that you thought was implemented successfully and explain _why_."|Forces the user to validate a specific effort, providing valuable qualitative data on what worked and why.|"Do you have any ideas?"|
|**Idea Generation**|"If you had to change one element of the project's interface or design, what would it be and why?"|Directs the reviewer to offer **constructive criticism** on a practical component of the project (interface/design).|"Tell me about your experience."|

### Key Takeaway: Quality over Quantity

It is always better to have **ten good, focused responses** than fifty vague ones. Use these examples to refine your own questions so that every answer you receive is directly useful for your evaluation report.